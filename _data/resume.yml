# 数据格式可以为 yaml(文件以.yml结尾) 或者json(文件以.json结尾)
# 如果YAML格式的数据请先检查格式是否有误，可选检查工具 http://www.yamllint.com

title: "刘嘉诚"
lang: "zh" #语言设置 zh表示中文 en 表示英语
name: "刘嘉诚"
jobtitle: "" #可空不显示
photo: "assets/img/photo.jpg" #照片可空，不显示

#联系方式
contact: #联系方式连接等3~5行
  - text: "liuterrific@hotmail.com" #文本内容
    href: 'mailto:liuterrific@hotmail.com' #链接，无链接则空
    icon: 'icons/email.svg' #图标 svg文件
  - text: "13057916678"
    href: 'tel:13057916678'
    icon: 'icons/phone.svg'
  - text: "mtman.site"
    href: 'https://llluno.github.io'
    icon: 'icons/web.svg'
  - text: "llluno"
    href: 'https://github.com/llluno'
    icon: "icons/github.svg"
    attr: 'target="_blank"' #新标签页打开
  - text: '1996.06'
    icon: "icons/shengri.svg"
    # - text: "地址"
    #   icon: "icons/location.svg"

#main下面是主体内容，类别条数不限
main: #简历主要内容，
  - type: Education #类别为ID
    name: 教育 #显示名称，空则使用type
    content: #内容基本格式 标题-副标题-日期-详细内容 (都允许空)
      - title: 浙江大学城市学院
        duration: "毕业年份：2019"
        sub: 信息管理与信息系统 学士
        detail: C语言程序设计，数据结构，Python程序设计基础，统计学，Java 程序设计基础，数据库原理，计算机网络组成原理，大数据数据挖掘与数据分析，信息管理学，GMC企业管理仿真

  - type: skills
    name: 技术
    content:
      - title: 技术栈（常用、熟练）
        items:
          - Java
          - Python
          - Scala
          - 爬虫
          - SQL
          - Linux常用命令
          - Markdown
          - spark sql / spark streaming
          - Hadoop
          - hive
          - zookeeper
          - flume
          - Kafka
          - SPSS
          - bpmn


      - title: 技术栈（用过、了解）
        items:
          - mongodb/redis
          - HBase
          - Docker
          - Kylin
          - Django
          - flink


      - title: 技术栈（学习中/计划学习）
        items:
          - TensorFlow
          - kubernetes
          - spark mllib
          - 代码整洁之道
          - 机器学习（周志华）

      - title: 英语及其他
        items:
          - CET4
          - GMC国际企业管理挑战赛国家三等奖

  - type: experience
    name: 工作经验
    content:
    - title: 大数据开发工程师
      sub: 深圳市火煋人科技有限公司
      duration: "2019年02月 - 2019年09月"
      tags:
      - spark
      - Hadoop
      detail: 主要负责spark开发，对数据进行统计以及对离线推荐的学习和应用。

    - title: 大数据开发工程师
      sub: 上海致宇信息科技有限公司
      duration: "2019年12月 - 至今"
      tags:
        - Java
        - CDH
        - Vue
      detail: 大数据产品的研发，大数据平台的开发
      
    - title: 大数据开发工程师
      sub: 乐清市大数据管理中心
      duration: "2020年5月 - 至今"
      tags:
        - Java
        - CDH
        - Python
        - Vue
        - CDC
        - DB
      detail: 数据运维工作，开发辅助性产品，负责数据仓的建设

  - type: projects
    name: 经历
    content:
      - title: 商品离线推荐服务
        duration: 2019年03月 - 2019年10月
        tags:
          - spark
          - Hadoop
          - hive
        detail: 离线推荐服务是综合用户所有的历史数据，利用设定的离线统计算法和离线推荐算法周期性的进行结果统计与保存，计算的结果在一定时间周期内是固定不变的，变更的频率取决于算法调度的频率。离线推荐服务主要计算一些可以预先进行统计和计算的指标，为实时计算和前端业务相应提供数据支撑。因为项目涉及保密协议，所以仅简单描述功能为样例。将用户访问商品产生的后端日志通过flume再通过spark导入到mongoDB，利用spark从mongoDB中读取数据，使用spark sql对商品的评分、浏览量、购买量等指标进行统计并存入mongoDB，再选用合适的推荐模型进行训练并计算误差。
        sub: 深圳市火煋人科技有限公司

      - title: 用户行为实时分析
        duration: 2019年07月-2019年09月
        tags:
          - flink
          - Kafka
        detail: 用户行为数据多样，整体可以分为用户行为习惯数据和业务行为数据两大类。用户的行为习惯数据包括了用户的登录方式、上线的时间点及时长、点击和浏览页面、页面停留时间以及页面跳转等等，我们可以从中进行流量统计和热门商品的统计，也可以深入挖掘用户的特征；这些数据往往可以从web服务器日志中直接读取到。而业务行为数据就是用户在电商平台中针对每个业务（通常是某个具体商品）所作的操作，我们一般会在业务系统中相应的位置埋点，然后收集日志进行分析。业务行为数据又可以简单分为两类：一类是能够明显地表现出用户兴趣的行为，比如对商品的收藏、喜欢、评分和评价，我们可以从中对数据进行深入分析，得到用户画像，进而对用户给出个性化的推荐商品列表，这个过程往往会用到机器学习相关的算法；另一类则是常规的业务操作，但需要着重关注一些异常状况以做好风控，比如登录和订单支付。<br>&nbsp;&nbsp;1、抽取出业务时间戳，告诉Flink框架基于业务时间做窗口<br>&nbsp;&nbsp;2、过滤出点击行为数据<br>&nbsp;&nbsp;3、按一小时的窗口大小，每5分钟统计一次，做滑动窗口聚合（Sliding Window）<br>&nbsp;&nbsp;4、按每个窗口聚合，输出每个窗口中点击量前N名的商品（ListState）<br>&nbsp;&nbsp;5、恶意登陆则可以通过CEP库来进行分析，通过设置pattern，将时间一秒内连续两次登陆视为恶意登陆
        sub: 自我学习项目
        
      - title: 杭州泰隆银行集群改造
        duration: 2019年12月-2020年2月
        tags:
          - Linux
          - 网络
        detail: 对需要改造的集群进行迁移，并进行统一安装Linux系统和大数据平台的安装。需要对集群的组网方式进行规划，由于对方集群采用跳板机的方式来控制集群安全，所以内部集群网络规划简单，IP地址顺序排序在已有集群之后，跳板机承担所有内外安全的问题，安装完所有服务器后进行IP设置，ntp同步等集群安装后需要做的。然后进行集群的网络测试并确定集群互通，通过CM来添加进大数据集群。
        sub: 上海致宇信息科技有限公司

      - title: 流程图引擎开发
        duration: 2020年1月-2022年4月
        tags:
          - bpmn
          - Vue
        detail: 大数据平台使用流程图引擎完成拖拉拽方式的快速配置，通过流程图引擎简化了大数据平台的操作，通过流程图引擎可以快速配置，拖出想要的节点来快速的配置一个流程任务，比如ETL过程通过流程图引擎，拖出数据源，指向一个转换任务，再指向数据落地的库。然后填写一些参数就可以快速的生成任务去运行。而不需要使用人员再去自己写代码。主要是通过Vue+bpmn.js做为前端页面。
        sub: 上海致宇信息科技有限公司

      - title: 银行数据报送平台
        duration: 2020年2月-2022年4月
        tags:
          - bpmn
          - Java
          - Vue
          - Mybatis
          - SpringBoot
        detail: 因涉及保密协议，只能大概的描述其中内容，通过SpringBoot+MyBatis实现后端功能，使用Vue来实现前端功能完成前后端分离，前端结合上一条流程图引擎，来完成数据报送的流程配置并由后端解析并配置相应的任务来调度对应的大数据组件去完成。流程图引擎的所有一些基础配置信息都通过后端传入前端动态生成。我在这个项目中主要涉及的是流程图引擎的开发、和一部分的后端开发。
        sub: 上海致宇信息科技有限公司
        
      - title: 政务服务事项自动分析
        duration: 2020年5月-2020年6月
        tags:
          - Python
          - Vue
          - MongoDB
        detail: 通过对政务服务事项的爬取，对政务服务事项中不符合规则的事项进行展示，并形成相应的excel报表，便于发送至部门通报。
        sub: 乐清市大数据管理中心
        
      
      - title: 数据运维与数据分析
        duration: 2020年5月-至今
        tags:
          - Python
          - DB
          - ODPS
        detail: 日常进行数据维护，保证数据任务正常，完成上级的各种数据分析任务，并提供相应的结果。
        sub: 乐清市大数据管理中心
      
      
      - title: 自动化上架温州平台接口
        duration: 2021年10月-2021年11月
        tags:
          - Python
          - DB
        detail: 本地共享平台已开出各种接口，人工上架温州平台仅能单条添加，通过自动化脚本做成可执行程序，通过填写好相应的模版，打开软件点击接口挂接，即可自动化进行温州平台的登录、接口的上线。
        sub: 乐清市大数据管理中心
        
      - title: 接口数据存储系统
        duration: 2022年3月-2022年4月
        tags:
          - Django
          - nginx
          - DB
        detail: 本地数据仅能通过数据库的形式进行流转，通过接口数据存储系统，将一些无法获取到系统数据库的实时数据通过接口传递至本系统，落地至本地数仓，来实现接口数据的本地存储。
        sub: 乐清市大数据管理中心
        
      - title: CDH集群
        duration: 2022年4月-2022年4月
        tags:
          - CDH
        detail: 本地缺少大数据集群，通过部署CDH集群，赋予大数据能力。
        sub: 乐清市大数据管理中心
        
      - title: 数据实时流转系统
        duration: 2022年4月-2022年6月
        tags:
          - CDH
          - canal
          - kafka
          - flink
          - zookeeper
          - grafana
        detail: 本地没有数据实时流转的能力，通过canal+kafka实现数据库的实时监测，将数据通过kafka进行实时流转，实现高效的数据流转，减少数据延迟，加快业务处置。
        sub: 乐清市大数据管理中心
        

      - title: 核酸检测智能预警机器人
        duration: 2022年4月-2022年8月
        tags:
          - Django
          - Vue
        detail: 通过核酸检测人员管理后台对人员进行维护后，自动将核酸检测预警信息发送至单位群内，实现核酸检测100%完成。
        sub: 乐清市大数据管理中心
      #可继续添加更多内容

#others 其他简略内容(列表)
others: #其他列表显示
  - type: others #ID可以为空
    name: '关于我'
    content: #选择需要的格式
      - title: 认真男孩
        text: " "

      - title: 兴趣
        list: #单行列表
          - 羽毛球；做饭；游泳；Vlog；阅读；
          - 喜欢学习去学新技术；愿意花时间去了解底层源码

      - title: 软优势
        list:
          - 适应能力强：能够快速融入新环境、新群体。
          - 抗压能力强：能够应对突发情况。
          - 学习能力强：搜索引擎 + CSDN + 官方文档能解决80%日常技术问题；善于检索和利用墙外丰富的技术资源；持续关注技术领域新闻动态。

#- type:
#  name: '其他'
#  content: #选择需要的格式
#  - 单行文字
#  - 如果有可以继续添加

#footer 脚注，打印版和web版不同不显示
footer: #脚注多组
  print: #打印版markdown或者html
  screen:
    #   href: '/'
    - text: "Made with &hearts; llluno"
      href: "https://github.com/NewFuture/CV/"

#页面额外js脚本，如xx统计
scripts:
#- src: "assets/js/resume.js"
#  defer: defer #可以设置defer或者sync异步加载
